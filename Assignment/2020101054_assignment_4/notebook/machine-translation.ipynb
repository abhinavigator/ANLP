{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6975832,"sourceType":"datasetVersion","datasetId":4008453}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW\nimport torch\nfrom torch import nn\nimport random\nimport json\n\nfrom torch.utils.data import DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-15T18:23:19.713651Z","iopub.execute_input":"2023-11-15T18:23:19.714476Z","iopub.status.idle":"2023-11-15T18:23:23.095867Z","shell.execute_reply.started":"2023-11-15T18:23:19.714437Z","shell.execute_reply":"2023-11-15T18:23:23.094808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_europarl_data(en_file, de_file):\n    with open(en_file, 'r', encoding='utf-8') as file_en, open(de_file, 'r', encoding='utf-8') as file_de:\n        texts_en = file_en.readlines()\n        texts_de = file_de.readlines()\n\n    # Ensure both lists have the same length\n    assert len(texts_en) == len(texts_de), \"Mismatch in line count between English and German files.\"\n    \n    return texts_en, texts_de\n\ntexts_en, texts_de = load_europarl_data('/kaggle/input/europart-dataset-for-task-3/de-en/europarl-v7.de-en.en', '/kaggle/input/europart-dataset-for-task-3/de-en/europarl-v7.de-en.de')\n\n\n# from torch.nn import DataParallel\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:23:24.186608Z","iopub.execute_input":"2023-11-15T18:23:24.187610Z","iopub.status.idle":"2023-11-15T18:23:26.175034Z","shell.execute_reply.started":"2023-11-15T18:23:24.187575Z","shell.execute_reply":"2023-11-15T18:23:26.173940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TranslationDataset(Dataset):\n    def __init__(self, texts_en, texts_de, tokenizer, max_length):\n        self.tokenizer = tokenizer\n        self.texts_en = texts_en  # List of English sentences\n        self.texts_de = texts_de  # List of corresponding German translations\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts_en)\n\n    def __getitem__(self, idx):\n        source_text = f\"[TRANSLATE EN DE] {self.texts_en[idx]}\"\n        target_text = self.texts_de[idx]\n\n        # Tokenize source and target texts\n        source_encoding = self.tokenizer(\n            source_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\"\n        )\n        target_encoding = self.tokenizer(\n            target_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\"\n        )\n\n        return {\n            'input_ids': source_encoding['input_ids'].flatten(),\n            'attention_mask': source_encoding['attention_mask'].flatten(),\n            'labels': target_encoding['input_ids'].flatten()\n        }\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:23:32.317889Z","iopub.execute_input":"2023-11-15T18:23:32.318651Z","iopub.status.idle":"2023-11-15T18:23:32.437812Z","shell.execute_reply.started":"2023-11-15T18:23:32.318611Z","shell.execute_reply":"2023-11-15T18:23:32.436639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:23:35.017447Z","iopub.execute_input":"2023-11-15T18:23:35.018142Z","iopub.status.idle":"2023-11-15T18:23:35.849737Z","shell.execute_reply.started":"2023-11-15T18:23:35.018107Z","shell.execute_reply":"2023-11-15T18:23:35.848813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and validation sets\ntrain_texts_en, val_texts_en, train_texts_de, val_texts_de = train_test_split(\n    texts_en, texts_de, test_size=0.1  # 10% for validation\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:23:37.808598Z","iopub.execute_input":"2023-11-15T18:23:37.809546Z","iopub.status.idle":"2023-11-15T18:23:39.620331Z","shell.execute_reply.started":"2023-11-15T18:23:37.809507Z","shell.execute_reply":"2023-11-15T18:23:39.619457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n\ntokenizer.pad_token = tokenizer.eos_token\n\n# Add special tokens and resize token embeddings in the model\nspecial_tokens_dict = {'additional_special_tokens': ['[TRANSLATE EN DE]']}\nnum_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n# model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:23:50.791474Z","iopub.execute_input":"2023-11-15T18:23:50.792324Z","iopub.status.idle":"2023-11-15T18:23:51.055272Z","shell.execute_reply.started":"2023-11-15T18:23:50.792282Z","shell.execute_reply":"2023-11-15T18:23:51.054155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Create datasets\ntrain_dataset = TranslationDataset(train_texts_en, train_texts_de, tokenizer, max_length=512)\nval_dataset = TranslationDataset(val_texts_en, val_texts_de, tokenizer, max_length=512)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:23:57.276333Z","iopub.execute_input":"2023-11-15T18:23:57.277438Z","iopub.status.idle":"2023-11-15T18:23:57.283003Z","shell.execute_reply.started":"2023-11-15T18:23:57.277387Z","shell.execute_reply":"2023-11-15T18:23:57.282092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:23:59.429288Z","iopub.execute_input":"2023-11-15T18:23:59.429670Z","iopub.status.idle":"2023-11-15T18:23:59.434320Z","shell.execute_reply.started":"2023-11-15T18:23:59.429640Z","shell.execute_reply":"2023-11-15T18:23:59.433091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DataLoaders\ntrain_dataloader = DataLoader(train_dataset, batch_size= batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size= batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:24:00.503344Z","iopub.execute_input":"2023-11-15T18:24:00.504222Z","iopub.status.idle":"2023-11-15T18:24:00.509745Z","shell.execute_reply.started":"2023-11-15T18:24:00.504183Z","shell.execute_reply":"2023-11-15T18:24:00.508597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained('gpt2')\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:24:01.913087Z","iopub.execute_input":"2023-11-15T18:24:01.913494Z","iopub.status.idle":"2023-11-15T18:24:04.834553Z","shell.execute_reply.started":"2023-11-15T18:24:01.913459Z","shell.execute_reply":"2023-11-15T18:24:04.833598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if CUDA is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:24:07.886365Z","iopub.execute_input":"2023-11-15T18:24:07.887101Z","iopub.status.idle":"2023-11-15T18:24:07.956479Z","shell.execute_reply.started":"2023-11-15T18:24:07.887065Z","shell.execute_reply":"2023-11-15T18:24:07.955270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move model to GPU\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:24:09.814897Z","iopub.execute_input":"2023-11-15T18:24:09.815714Z","iopub.status.idle":"2023-11-15T18:24:11.756637Z","shell.execute_reply.started":"2023-11-15T18:24:09.815673Z","shell.execute_reply":"2023-11-15T18:24:11.755617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:24:11.997195Z","iopub.execute_input":"2023-11-15T18:24:11.997951Z","iopub.status.idle":"2023-11-15T18:24:12.006303Z","shell.execute_reply.started":"2023-11-15T18:24:11.997917Z","shell.execute_reply":"2023-11-15T18:24:12.005272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number_of_epochs = 1","metadata":{"execution":{"iopub.status.busy":"2023-11-15T18:24:21.067108Z","iopub.execute_input":"2023-11-15T18:24:21.067779Z","iopub.status.idle":"2023-11-15T18:24:21.072299Z","shell.execute_reply.started":"2023-11-15T18:24:21.067729Z","shell.execute_reply":"2023-11-15T18:24:21.071146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(number_of_epochs):\n    model.train()\n    total_train_loss = 0\n\n    for batch in train_dataloader:\n        optimizer.zero_grad()\n\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_train_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n\n    average_train_loss = total_train_loss / len(train_dataloader)\n    print(f'Epoch {epoch + 1}/{number_of_epochs}, Training Loss: {average_train_loss:.4f}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Validation step\n    model.eval()\n    total_val_loss = 0\n    with torch.no_grad():\n        for batch in val_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            total_val_loss += loss.item()\n\n    average_val_loss = total_val_loss / len(val_dataloader)\n    print(f'Epoch {epoch + 1}/{number_of_epochs}, Validation Loss: {average_val_loss:.4f}')","metadata":{},"execution_count":null,"outputs":[]}]}
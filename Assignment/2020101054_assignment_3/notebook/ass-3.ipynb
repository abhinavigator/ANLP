{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6642866,"sourceType":"datasetVersion","datasetId":3834745},{"sourceId":6713813,"sourceType":"datasetVersion","datasetId":3868841}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from transformer import Transformer # this is the transformer.py file\nimport torch\nimport numpy as np","metadata":{"_uuid":"765d609d-37bd-4a72-871b-0c7839daf285","_cell_guid":"8d373b2c-8440-4547-b8d0-870cb44088e7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:33.463209Z","iopub.execute_input":"2023-10-16T22:55:33.463979Z","iopub.status.idle":"2023-10-16T22:55:39.822816Z","shell.execute_reply.started":"2023-10-16T22:55:33.463950Z","shell.execute_reply":"2023-10-16T22:55:39.821763Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/check-transformer\")\n\nfrom transformer import Transformer","metadata":{"_uuid":"9b2090de-29b0-4549-b46c-6b0613121a56","_cell_guid":"a1924d53-b6f4-4b97-ab2e-212648b31ebf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:39.824717Z","iopub.execute_input":"2023-10-16T22:55:39.825162Z","iopub.status.idle":"2023-10-16T22:55:39.848394Z","shell.execute_reply.started":"2023-10-16T22:55:39.825131Z","shell.execute_reply":"2023-10-16T22:55:39.847589Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# from transformer_test import Transformer","metadata":{"_uuid":"981a423a-c7f4-44db-a7cb-7899b96fa321","_cell_guid":"aec98422-9624-460e-8483-c5bdfff7a8f1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:39.850324Z","iopub.execute_input":"2023-10-16T22:55:39.850619Z","iopub.status.idle":"2023-10-16T22:55:39.855319Z","shell.execute_reply.started":"2023-10-16T22:55:39.850590Z","shell.execute_reply":"2023-10-16T22:55:39.853994Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_english_file = '/kaggle/input/assignment-3-dataset/ted-talks-corpus/train.en'\ntrain_french_file ='/kaggle/input/assignment-3-dataset/ted-talks-corpus/train.fr'","metadata":{"_uuid":"3316c549-816f-4dca-a46e-19ec4f543aba","_cell_guid":"682fd579-ee83-461e-8674-63d4bec4aa6a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:39.858985Z","iopub.execute_input":"2023-10-16T22:55:39.859619Z","iopub.status.idle":"2023-10-16T22:55:39.867918Z","shell.execute_reply.started":"2023-10-16T22:55:39.859598Z","shell.execute_reply":"2023-10-16T22:55:39.866988Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"valid_english_file = '/kaggle/input/assignment-3-dataset/ted-talks-corpus/dev.en'\nvalid_french_file = '/kaggle/input/assignment-3-dataset/ted-talks-corpus/dev.fr'","metadata":{"_uuid":"df91ed6c-ba1c-4be1-8498-130a4eff422c","_cell_guid":"d47bb75f-89c1-47fd-8cf7-12a9fbfc8a12","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:39.869331Z","iopub.execute_input":"2023-10-16T22:55:39.869856Z","iopub.status.idle":"2023-10-16T22:55:39.890132Z","shell.execute_reply.started":"2023-10-16T22:55:39.869826Z","shell.execute_reply":"2023-10-16T22:55:39.889301Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"test_english_file = '/kaggle/input/assignment-3-dataset/ted-talks-corpus/test.en'\ntest_french_file = '/kaggle/input/assignment-3-dataset/ted-talks-corpus/test.fr'","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:39.891049Z","iopub.execute_input":"2023-10-16T22:55:39.891391Z","iopub.status.idle":"2023-10-16T22:55:39.911641Z","shell.execute_reply.started":"2023-10-16T22:55:39.891361Z","shell.execute_reply":"2023-10-16T22:55:39.910632Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_french_file","metadata":{"_uuid":"c5c81600-be7c-4963-b049-0107fce5c193","_cell_guid":"449e90be-bdde-48e7-9a50-22c09b5738a5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:39.912754Z","iopub.execute_input":"2023-10-16T22:55:39.913455Z","iopub.status.idle":"2023-10-16T22:55:39.937962Z","shell.execute_reply.started":"2023-10-16T22:55:39.913039Z","shell.execute_reply":"2023-10-16T22:55:39.937150Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/assignment-3-dataset/ted-talks-corpus/train.fr'"},"metadata":{}}]},{"cell_type":"code","source":"valid_french_file","metadata":{"_uuid":"0ba7b69f-1e3b-4ee7-983b-76f3063d81c3","_cell_guid":"208f0ca1-0d2e-4ac6-98f0-30684ae7b364","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:39.940136Z","iopub.execute_input":"2023-10-16T22:55:39.942273Z","iopub.status.idle":"2023-10-16T22:55:39.960051Z","shell.execute_reply.started":"2023-10-16T22:55:39.942244Z","shell.execute_reply":"2023-10-16T22:55:39.959276Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/assignment-3-dataset/ted-talks-corpus/dev.fr'"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"b4ee93a1-8922-480d-ae1d-a56dd69ecf8b","_cell_guid":"dd10284a-6f1d-4135-90eb-98939ce59d64","trusted":true}},{"cell_type":"code","source":"START_TOKEN = '<START>'\nPADDING_TOKEN = '<PADDING>'\nEND_TOKEN = '<END>'","metadata":{"_uuid":"0809b5c9-7349-46b7-96f7-796a061afb74","_cell_guid":"3d581f84-1b21-4a80-87f7-5553d291e769","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:39.960829Z","iopub.execute_input":"2023-10-16T22:55:39.961145Z","iopub.status.idle":"2023-10-16T22:55:39.980399Z","shell.execute_reply.started":"2023-10-16T22:55:39.961110Z","shell.execute_reply":"2023-10-16T22:55:39.979513Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n                        ':', '<', '=', '>', '?', '@',\n                        '[', '\\\\', ']', '^', '_', '`', \n                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n                        'y', 'z', \n                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n\n\nfrench_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n                     '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n                     ':', '<', '=', '>', '?', '@',\n                     '[', '\\\\', ']', '^', '_', '`', \n                     'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n                     'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n                     'y', 'z', \n                     'à', 'â', 'ç', 'é', 'è', 'ê', 'ë', 'î', 'ï', 'ô', 'ù', 'û', 'ü', 'ÿ',\n                     'œ', 'æ', '€',  # Additional French-specific characters\n                     '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]","metadata":{"_uuid":"3ff9e746-32b6-4d1a-9241-99b56d409698","_cell_guid":"0dcd950f-e118-4253-8128-1350fe320c36","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:39.985044Z","iopub.execute_input":"2023-10-16T22:55:39.985310Z","iopub.status.idle":"2023-10-16T22:55:40.002957Z","shell.execute_reply.started":"2023-10-16T22:55:39.985291Z","shell.execute_reply":"2023-10-16T22:55:40.001975Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"index_to_french = {k:v for k,v in enumerate(french_vocabulary)}\nfrench_to_index = {v:k for k,v in enumerate(french_vocabulary)}\nindex_to_english = {k:v for k,v in enumerate(english_vocabulary)}\nenglish_to_index = {v:k for k,v in enumerate(english_vocabulary)}","metadata":{"_uuid":"0b49341c-ecdb-44e6-b441-242e6ccc7728","_cell_guid":"0aae34c9-ccc0-495f-90c1-edd9781153ae","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.007017Z","iopub.execute_input":"2023-10-16T22:55:40.009100Z","iopub.status.idle":"2023-10-16T22:55:40.028988Z","shell.execute_reply.started":"2023-10-16T22:55:40.009054Z","shell.execute_reply":"2023-10-16T22:55:40.028046Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"753d8f16-ef4a-40a1-b3b7-8b72bc93f589","_cell_guid":"904ad4b5-7641-4794-854c-d32327f07b58","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(train_english_file, 'r') as file:\n    train_english_sentences = file.readlines()\nwith open(train_french_file, 'r') as file:\n    train_french_sentences = file.readlines()","metadata":{"_uuid":"5c4f9d97-dac4-4ce1-aac6-87f760fdb077","_cell_guid":"41d8e0bf-3534-42d3-98c8-b2d5cff75094","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.030013Z","iopub.execute_input":"2023-10-16T22:55:40.030778Z","iopub.status.idle":"2023-10-16T22:55:40.176448Z","shell.execute_reply.started":"2023-10-16T22:55:40.030749Z","shell.execute_reply":"2023-10-16T22:55:40.175391Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"with open(valid_english_file, 'r') as file:\n    valid_english_sentences = file.readlines()\nwith open(valid_french_file, 'r') as file:\n    valid_french_sentences = file.readlines()","metadata":{"_uuid":"dcae85ef-dba1-4f92-85b7-2c4f5c959f46","_cell_guid":"92dd8caa-420d-409e-8a56-c8a30c6c71ca","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.180896Z","iopub.execute_input":"2023-10-16T22:55:40.183422Z","iopub.status.idle":"2023-10-16T22:55:40.215719Z","shell.execute_reply.started":"2023-10-16T22:55:40.183384Z","shell.execute_reply":"2023-10-16T22:55:40.214773Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"with open(test_english_file, 'r') as file:\n    test_english_sentences = file.readlines()\nwith open(test_french_file, 'r') as file:\n    test_french_sentences = file.readlines()","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:40.219594Z","iopub.execute_input":"2023-10-16T22:55:40.221907Z","iopub.status.idle":"2023-10-16T22:55:40.256943Z","shell.execute_reply.started":"2023-10-16T22:55:40.221859Z","shell.execute_reply":"2023-10-16T22:55:40.256111Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# valid_english_sentences","metadata":{"_uuid":"d29e2a2f-4413-41de-af03-0c27e90c8ac0","_cell_guid":"77febe7c-426a-414d-9e3d-66c5c53b330d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.258044Z","iopub.execute_input":"2023-10-16T22:55:40.258598Z","iopub.status.idle":"2023-10-16T22:55:40.264716Z","shell.execute_reply.started":"2023-10-16T22:55:40.258566Z","shell.execute_reply":"2023-10-16T22:55:40.263679Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# train_french_sentences","metadata":{"_uuid":"4cb7453b-2e7a-4c10-aee6-59c4b8a643ee","_cell_guid":"b06fd6d9-d872-4bff-a0ce-fe9f28b49c32","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.268159Z","iopub.execute_input":"2023-10-16T22:55:40.269317Z","iopub.status.idle":"2023-10-16T22:55:40.277765Z","shell.execute_reply.started":"2023-10-16T22:55:40.269285Z","shell.execute_reply":"2023-10-16T22:55:40.276850Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_english_sentences = [sentence.rstrip('\\n').lower() for sentence in train_english_sentences]\ntrain_french_sentences = [sentence.rstrip('\\n').lower() for sentence in train_french_sentences]","metadata":{"_uuid":"41c99cdc-e766-47cb-b199-d1f7a6c88aea","_cell_guid":"9d940f67-9e9e-4c53-a68f-a8495e423029","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.279045Z","iopub.execute_input":"2023-10-16T22:55:40.279611Z","iopub.status.idle":"2023-10-16T22:55:40.394202Z","shell.execute_reply.started":"2023-10-16T22:55:40.279580Z","shell.execute_reply":"2023-10-16T22:55:40.393260Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"valid_english_sentences = [sentence.rstrip('\\n').lower() for sentence in valid_english_sentences]\nvalid_french_sentences = [sentence.rstrip('\\n').lower() for sentence in valid_french_sentences]","metadata":{"_uuid":"220a422b-d5d9-4e7f-bd5d-b17ef460b71c","_cell_guid":"eb0d7abb-9aa5-47f9-bf38-65f2afe45af8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.398092Z","iopub.execute_input":"2023-10-16T22:55:40.400047Z","iopub.status.idle":"2023-10-16T22:55:40.408987Z","shell.execute_reply.started":"2023-10-16T22:55:40.400015Z","shell.execute_reply":"2023-10-16T22:55:40.408198Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test_english_sentences = [sentence.rstrip('\\n').lower() for sentence in test_english_sentences]\ntest_french_sentences = [sentence.rstrip('\\n').lower() for sentence in test_french_sentences]","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:40.412785Z","iopub.execute_input":"2023-10-16T22:55:40.415016Z","iopub.status.idle":"2023-10-16T22:55:40.427602Z","shell.execute_reply.started":"2023-10-16T22:55:40.414986Z","shell.execute_reply":"2023-10-16T22:55:40.426341Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_english_sentences[:10]","metadata":{"_uuid":"c7bfbad7-80b7-43aa-a12d-af111bc27f0b","_cell_guid":"2305cfe3-b3a3-4d6c-9f7d-f76009935292","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.429232Z","iopub.execute_input":"2023-10-16T22:55:40.429573Z","iopub.status.idle":"2023-10-16T22:55:40.443206Z","shell.execute_reply.started":"2023-10-16T22:55:40.429541Z","shell.execute_reply":"2023-10-16T22:55:40.442294Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[\"david gallo: this is bill lange. i'm dave gallo.\",\n \"and we're going to tell you some stories from the sea here in video.\",\n \"we've got some of the most incredible video of titanic that's ever been seen, and we're not going to show you any of it.\",\n \"the truth of the matter is that the titanic -- even though it's breaking all sorts of box office records -- it's not the most exciting story from the sea.\",\n 'and the problem, i think, is that we take the ocean for granted.',\n 'when you think about it, the oceans are 75 percent of the planet.',\n 'most of the planet is ocean water.',\n 'the average depth is about two miles.',\n \"part of the problem, i think, is we stand at the beach, or we see images like this of the ocean, and you look out at this great big blue expanse, and it's shimmering and it's moving and there's waves and there's surf and there's tides, but you have no idea for what lies in there.\",\n 'and in the oceans, there are the longest mountain ranges on the planet.']"},"metadata":{}}]},{"cell_type":"code","source":"valid_english_sentences[:10]","metadata":{"_uuid":"ee8d87b6-3276-4262-8027-3fffc73b8b59","_cell_guid":"8d249007-63c3-45da-b7f5-82738a46e096","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.444310Z","iopub.execute_input":"2023-10-16T22:55:40.445222Z","iopub.status.idle":"2023-10-16T22:55:40.457383Z","shell.execute_reply.started":"2023-10-16T22:55:40.445193Z","shell.execute_reply":"2023-10-16T22:55:40.456471Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['you know, one of the intense pleasures of travel and one of the delights of ethnographic research is the opportunity to live amongst those who have not forgotten the old ways, who still feel their past in the wind, touch it in stones polished by rain, taste it in the bitter leaves of plants.',\n 'just to know that jaguar shamans still journey beyond the milky way, or the myths of the inuit elders still resonate with meaning, or that in the himalaya, the buddhists still pursue the breath of the dharma, is to really remember the central revelation of anthropology, and that is the idea that the world in which we live does not exist in some absolute sense, but is just one model of reality, the consequence of one particular set of adaptive choices that our lineage made, albeit successfully, many generations ago.',\n 'and of course, we all share the same adaptive imperatives.',\n \"we're all born. we all bring our children into the world.\",\n 'we go through initiation rites.',\n \"we have to deal with the inexorable separation of death, so it shouldn't surprise us that we all sing, we all dance, we all have art.\",\n \"but what's interesting is the unique cadence of the song, the rhythm of the dance in every culture.\",\n 'and whether it is the penan in the forests of borneo, or the voodoo acolytes in haiti, or the warriors in the kaisut desert of northern kenya, the curandero in the mountains of the andes, or a caravanserai in the middle of the sahara -- this is incidentally the fellow that i traveled into the desert with a month ago -- or indeed a yak herder in the slopes of qomolangma, everest, the goddess mother of the world.',\n 'all of these peoples teach us that there are other ways of being, other ways of thinking, other ways of orienting yourself in the earth.',\n 'and this is an idea, if you think about it, can only fill you with hope.']"},"metadata":{}}]},{"cell_type":"code","source":"train_french_sentences[:10]","metadata":{"_uuid":"789db334-baf8-47df-9db4-b1de02ea3f3e","_cell_guid":"6d2064f4-e1a0-47d9-a5c9-b9111871e3dd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.458693Z","iopub.execute_input":"2023-10-16T22:55:40.459313Z","iopub.status.idle":"2023-10-16T22:55:40.469108Z","shell.execute_reply.started":"2023-10-16T22:55:40.459275Z","shell.execute_reply":"2023-10-16T22:55:40.468137Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['david gallo: voici bill lange. je suis dave gallo.',\n 'nous allons vous raconter quelques histoires de la mer en vidéo.',\n \"nous avons des vidéos du titanic parmi les plus spectaculaires jamais vues. et nous n'allons pas vous en montrer une image.\",\n \"la vérité est que le titanic -- même s'il continue de battre toutes les records de recettes -- n'est pas l'histoire la plus passionnante.\",\n \"le problème, je crois, est qu'on tient l'océan pour acquis.\",\n 'quand vous y pensez, les océans représentent 75% de la planète.',\n \"la plus grande partie de la planète est d'eau.\",\n 'la profondeur moyenne est environ 3,2 km.',\n \"une partie du problème, je pense, est qu'en étant sur la plage ou en regardant des images de l'océan, comme celles-ci, on voit cette grande étendue bleue, chatoyante, ça bouge, il y a des vagues, il y a du surf et il y a des marées, mais vous n'avez aucune idée de ce qui s'y cache.\",\n 'il y existe les chaînes de montagnes les plus longues de la planète.']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"_uuid":"69f92508-a4d9-408f-a0a8-1ab3b2835640","_cell_guid":"9249772c-ad3a-4639-9860-ea50dcb825b0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nPERCENTILE = 97\nprint( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in train_english_sentences], PERCENTILE)}\" )\nprint( f\"{PERCENTILE}th percentile length french: {np.percentile([len(x) for x in train_french_sentences], PERCENTILE)}\" )","metadata":{"_uuid":"f1482ca6-19a9-4b95-94fc-89c8166ed541","_cell_guid":"0fc83fab-5f80-4420-b929-be9c5274906a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.470455Z","iopub.execute_input":"2023-10-16T22:55:40.470935Z","iopub.status.idle":"2023-10-16T22:55:40.498483Z","shell.execute_reply.started":"2023-10-16T22:55:40.470907Z","shell.execute_reply":"2023-10-16T22:55:40.497630Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"97th percentile length English: 273.0\n97th percentile length french: 308.0\n","output_type":"stream"}]},{"cell_type":"code","source":"len(train_french_sentences)","metadata":{"_uuid":"a454742e-ca8c-4b48-a7b4-7d8d2f28dc9f","_cell_guid":"5901c886-2bfc-442a-9d24-00cfb3b5ecb2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.499642Z","iopub.execute_input":"2023-10-16T22:55:40.500217Z","iopub.status.idle":"2023-10-16T22:55:40.505501Z","shell.execute_reply.started":"2023-10-16T22:55:40.500190Z","shell.execute_reply":"2023-10-16T22:55:40.504663Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"30000"},"metadata":{}}]},{"cell_type":"code","source":"len(test_french_sentences)","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:40.506663Z","iopub.execute_input":"2023-10-16T22:55:40.507242Z","iopub.status.idle":"2023-10-16T22:55:40.521471Z","shell.execute_reply.started":"2023-10-16T22:55:40.507211Z","shell.execute_reply":"2023-10-16T22:55:40.520516Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"1305"},"metadata":{}}]},{"cell_type":"code","source":"max_sequence_length = 350\n\ndef is_valid_tokens(sentence, vocab):\n    for token in list(set(sentence)):\n        if token not in vocab:\n            return False\n    return True\n\ndef is_valid_length(sentence, max_sequence_length):\n    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n\nvalid_sentence_indicies = []\nfor index in range(len(train_french_sentences)):\n    train_french_sentence, train_english_sentence = train_french_sentences[index], train_english_sentences[index]\n    if is_valid_length(train_french_sentence, max_sequence_length) \\\n      and is_valid_length(train_english_sentence, max_sequence_length) \\\n      and is_valid_tokens(train_french_sentence, french_vocabulary):\n        valid_sentence_indicies.append(index)\n\nprint(f\"Number of sentences: {len(train_english_sentences)}\")\nprint(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")","metadata":{"_uuid":"645c5062-013a-4a7b-8045-93a8a9766ea3","_cell_guid":"43c02bab-44e4-4a20-ba4b-ef7d83e16fd7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:40.523055Z","iopub.execute_input":"2023-10-16T22:55:40.523696Z","iopub.status.idle":"2023-10-16T22:55:41.164004Z","shell.execute_reply.started":"2023-10-16T22:55:40.523668Z","shell.execute_reply":"2023-10-16T22:55:41.162984Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Number of sentences: 30000\nNumber of valid sentences: 27285\n","output_type":"stream"}]},{"cell_type":"code","source":"max_sequence_length = 350\n\n# Function to check if tokens in a sentence are valid in the given vocabulary\ndef is_valid_tokens(sentence, vocab):\n    for token in list(set(sentence)):\n        if token not in vocab:\n            return False\n    return True\n\n# Function to check if the length of a sentence is valid\ndef is_valid_length(sentence, max_sequence_length):\n    return len(sentence) < (max_sequence_length - 1)  # need to re-add the end token so leaving 1 space\n\n# Function to filter sentences and create a valid sentence indices list\ndef filter_valid_sentences(sentences, vocab, max_length):\n    valid_sentence_indices = []\n    for index in range(len(sentences)):\n        sentence = sentences[index]\n        if is_valid_length(sentence, max_length) and is_valid_tokens(sentence, vocab):\n            valid_sentence_indices.append(index)\n    return valid_sentence_indices\n\n# Filter the training sentences for valid indices\nvalid_train_sentence_indices = filter_valid_sentences(train_french_sentences, french_vocabulary, max_sequence_length)\n\n# Filter the validation sentences for valid indices\nvalid_validation_sentence_indices = filter_valid_sentences(valid_french_sentences, french_vocabulary, max_sequence_length)\n\nprint(f\"Number of training sentences: {len(train_french_sentences)}\")\nprint(f\"Number of valid training sentences: {len(valid_train_sentence_indices)}\")\n\nprint(f\"Number of validation sentences: {len(valid_french_sentences)}\")\nprint(f\"Number of valid validation sentences: {len(valid_validation_sentence_indices)}\")","metadata":{"_uuid":"6f845940-bf26-46ad-ba8e-f65fe6d5d9de","_cell_guid":"cfd5274c-ba3d-48d3-b67b-60db6c48c18d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:41.165220Z","iopub.execute_input":"2023-10-16T22:55:41.165974Z","iopub.status.idle":"2023-10-16T22:55:41.925616Z","shell.execute_reply.started":"2023-10-16T22:55:41.165942Z","shell.execute_reply":"2023-10-16T22:55:41.924712Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Number of training sentences: 30000\nNumber of valid training sentences: 27293\nNumber of validation sentences: 887\nNumber of valid validation sentences: 829\n","output_type":"stream"}]},{"cell_type":"code","source":"test_valid_sentence_indices = filter_valid_sentences(test_french_sentences, french_vocabulary, max_sequence_length)","metadata":{"_uuid":"1c7ecbea-ce9d-41a2-8dff-8abed6e1372a","_cell_guid":"f815750c-ddba-40eb-95ea-566f504d67d0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:41.942327Z","iopub.execute_input":"2023-10-16T22:55:41.948113Z","iopub.status.idle":"2023-10-16T22:55:42.011809Z","shell.execute_reply.started":"2023-10-16T22:55:41.948052Z","shell.execute_reply":"2023-10-16T22:55:42.010965Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of test sentences: {len(test_french_sentences)}\")\nprint(f\"Number of test valid sentences: {len(test_valid_sentence_indices)}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:42.013110Z","iopub.execute_input":"2023-10-16T22:55:42.013747Z","iopub.status.idle":"2023-10-16T22:55:42.020774Z","shell.execute_reply.started":"2023-10-16T22:55:42.013712Z","shell.execute_reply":"2023-10-16T22:55:42.019880Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Number of test sentences: 1305\nNumber of test valid sentences: 1181\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"_uuid":"626d4b27-2247-49d4-b338-879c03c231c2","_cell_guid":"29d36cac-9c18-4971-999a-30f2235af6c6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if the sentence is more than 350 it is not a valid sentence","metadata":{"_uuid":"674890ab-9531-4c05-a272-c8ceccc3e74f","_cell_guid":"26ff621a-b64c-4b76-be47-3e1081d4cede","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.022025Z","iopub.execute_input":"2023-10-16T22:55:42.022931Z","iopub.status.idle":"2023-10-16T22:55:42.029581Z","shell.execute_reply.started":"2023-10-16T22:55:42.022901Z","shell.execute_reply":"2023-10-16T22:55:42.028457Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_french_sentences = [train_french_sentences[i] for i in valid_sentence_indicies]\ntrain_english_sentences = [train_english_sentences[i] for i in valid_sentence_indicies]","metadata":{"_uuid":"f2ae017b-7623-48e1-98a5-894f24fa665c","_cell_guid":"ba55e929-e52a-4b95-87fb-3f48d1f9d750","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.030747Z","iopub.execute_input":"2023-10-16T22:55:42.031327Z","iopub.status.idle":"2023-10-16T22:55:42.057474Z","shell.execute_reply.started":"2023-10-16T22:55:42.031284Z","shell.execute_reply":"2023-10-16T22:55:42.056404Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"valid_french_sentences = [valid_french_sentences[i] for i in valid_validation_sentence_indices]\nvalid_english_sentences = [valid_english_sentences[i] for i in valid_validation_sentence_indices]","metadata":{"_uuid":"ee627fbf-f5b1-4c50-9cb7-b2fbd9f1d43b","_cell_guid":"4fd0f24c-7c10-48d5-b57d-bbe76e982d87","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.058742Z","iopub.execute_input":"2023-10-16T22:55:42.063990Z","iopub.status.idle":"2023-10-16T22:55:42.084349Z","shell.execute_reply.started":"2023-10-16T22:55:42.063954Z","shell.execute_reply":"2023-10-16T22:55:42.083234Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"test_french_sentences = [test_french_sentences[i] for i in test_valid_sentence_indices]\ntest_english_sentences = [test_english_sentences[i] for i in test_valid_sentence_indices]","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:42.090713Z","iopub.execute_input":"2023-10-16T22:55:42.091322Z","iopub.status.idle":"2023-10-16T22:55:42.105292Z","shell.execute_reply.started":"2023-10-16T22:55:42.091293Z","shell.execute_reply":"2023-10-16T22:55:42.104319Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"test_english_sentences[:3]","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:42.109027Z","iopub.execute_input":"2023-10-16T22:55:42.109424Z","iopub.status.idle":"2023-10-16T22:55:42.125841Z","shell.execute_reply.started":"2023-10-16T22:55:42.109395Z","shell.execute_reply":"2023-10-16T22:55:42.124014Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"['when i was in my 20s, i saw my very first psychotherapy client.',\n 'i was a ph.d. student in clinical psychology at berkeley.',\n 'she was a 26-year-old woman named alex.']"},"metadata":{}}]},{"cell_type":"code","source":"valid_french_sentences[:2]","metadata":{"_uuid":"1a3c99a1-c267-4c73-93f4-004329c743a1","_cell_guid":"e49c7700-8426-4ea8-8dfa-f42b10ec1d57","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.127325Z","iopub.execute_input":"2023-10-16T22:55:42.127757Z","iopub.status.idle":"2023-10-16T22:55:42.142228Z","shell.execute_reply.started":"2023-10-16T22:55:42.127671Z","shell.execute_reply":"2023-10-16T22:55:42.139869Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[\"vous savez, un des plaisirs intenses du voyage et un des délices de la recherche ethnographique est la possibilité de vivre parmi ceux qui n'ont pas oublié les anciennes coutumes, qui ressentent encore leur passé souffler dans le vent, qui le touchent dans les pierres polies par la pluie, le dégustent dans les feuilles amères des plantes.\",\n \"bien sûr, nous partageons tous les mêmes impératifs d'adaptation.\"]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"_uuid":"371ae270-3780-45ff-9065-c5ca35768fdc","_cell_guid":"7f20d432-8777-40dc-8d6b-ceadff0f83e9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_french_sentences[:3]","metadata":{"_uuid":"a8d7af16-b244-43bc-a947-d9b298383184","_cell_guid":"9716f748-7775-4700-8ed9-1d22d87b5581","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.146220Z","iopub.execute_input":"2023-10-16T22:55:42.146528Z","iopub.status.idle":"2023-10-16T22:55:42.163945Z","shell.execute_reply.started":"2023-10-16T22:55:42.146500Z","shell.execute_reply":"2023-10-16T22:55:42.163039Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"['david gallo: voici bill lange. je suis dave gallo.',\n 'nous allons vous raconter quelques histoires de la mer en vidéo.',\n \"nous avons des vidéos du titanic parmi les plus spectaculaires jamais vues. et nous n'allons pas vous en montrer une image.\"]"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\nd_model = 512\nbatch_size = 30\nffn_hidden = 2048\nnum_heads = 8\ndrop_prob = 0.1\nnum_layers = 2\nmax_sequence_length = 350\nfrench_vocab_size = len(french_vocabulary)\n\ntransformer = Transformer(d_model, \n                          ffn_hidden,\n                          num_heads, \n                          drop_prob, \n                          num_layers, \n                          max_sequence_length,\n                          french_vocab_size,\n                          english_to_index,\n                          french_to_index,\n                          START_TOKEN, \n                          END_TOKEN, \n                          PADDING_TOKEN)","metadata":{"_uuid":"59cf4fb7-5f98-4490-8a1d-5e48c0f8de3d","_cell_guid":"cc8fded4-9ada-42fc-98df-81b3d3c0c902","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.165310Z","iopub.execute_input":"2023-10-16T22:55:42.165968Z","iopub.status.idle":"2023-10-16T22:55:42.392557Z","shell.execute_reply.started":"2023-10-16T22:55:42.165938Z","shell.execute_reply":"2023-10-16T22:55:42.391865Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"transformer","metadata":{"_uuid":"c05838e7-dc53-456d-9db9-459f4ff98d4f","_cell_guid":"fd5f15d6-9268-4882-a95b-d93bba0a4964","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.393726Z","iopub.execute_input":"2023-10-16T22:55:42.394096Z","iopub.status.idle":"2023-10-16T22:55:42.400850Z","shell.execute_reply.started":"2023-10-16T22:55:42.394048Z","shell.execute_reply":"2023-10-16T22:55:42.399878Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Transformer(\n  (encoder): Encoder(\n    (sentence_embedding): SentenceEmbedding(\n      (embedding): Embedding(71, 512)\n      (position_encoder): PositionalEncoding()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layers): SequentialEncoder(\n      (0): EncoderLayer(\n        (attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (decoder): Decoder(\n    (sentence_embedding): SentenceEmbedding(\n      (embedding): Embedding(88, 512)\n      (position_encoder): PositionalEncoding()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layers): SequentialDecoder(\n      (0): DecoderLayer(\n        (self_attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (encoder_decoder_attention): MultiHeadCrossAttention(\n          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (layer_norm3): LayerNormalization()\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (linear): Linear(in_features=512, out_features=88, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass TextDataset(Dataset):\n\n    def __init__(self, train_english_sentences, train_french_sentences):\n        self.train_english_sentences = train_english_sentences\n        self.train_french_sentences = train_french_sentences\n\n    def __len__(self):\n        return len(self.train_english_sentences)\n\n    def __getitem__(self, idx):\n        return self.train_english_sentences[idx], self.train_french_sentences[idx]","metadata":{"_uuid":"bce0c381-8905-4997-80b0-d0ec10c1e04a","_cell_guid":"d560b424-792d-4fd5-9d90-760bbb4b8fac","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.402218Z","iopub.execute_input":"2023-10-16T22:55:42.402785Z","iopub.status.idle":"2023-10-16T22:55:42.418822Z","shell.execute_reply.started":"2023-10-16T22:55:42.402753Z","shell.execute_reply":"2023-10-16T22:55:42.417967Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# dataloader for validation set\n\nclass TextDataset(Dataset):\n\n    def __init__(self, valid_english_sentences, valid_french_sentences):\n        self.valid_english_sentences = valid_english_sentences\n        self.valid_french_sentences = valid_french_sentences\n\n    def __len__(self):\n        return len(self.valid_english_sentences)\n\n    def __getitem__(self, idx):\n        return self.valid_english_sentences[idx], self.valid_french_sentences[idx]","metadata":{"_uuid":"cb35cebf-c3b9-4d2a-90d6-6392804633af","_cell_guid":"458e72e7-f08a-4971-9118-96da32101460","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.420093Z","iopub.execute_input":"2023-10-16T22:55:42.421053Z","iopub.status.idle":"2023-10-16T22:55:42.430983Z","shell.execute_reply.started":"2023-10-16T22:55:42.421023Z","shell.execute_reply":"2023-10-16T22:55:42.430107Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# dataloader for test set \nclass TextDataset(Dataset):\n\n    def __init__(self, test_english_sentences, test_french_sentences):\n        self.test_english_sentences = test_english_sentences\n        self.test_french_sentences = test_french_sentences\n\n    def __len__(self):\n        return len(self.test_english_sentences)\n\n    def __getitem__(self, idx):\n        return self.test_english_sentences[idx], self.test_french_sentences[idx]","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:42.432343Z","iopub.execute_input":"2023-10-16T22:55:42.432695Z","iopub.status.idle":"2023-10-16T22:55:42.448633Z","shell.execute_reply.started":"2023-10-16T22:55:42.432663Z","shell.execute_reply":"2023-10-16T22:55:42.447785Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"dataset = TextDataset(train_english_sentences, train_french_sentences)","metadata":{"_uuid":"b6d9b249-3470-4f9e-9e79-99404589d120","_cell_guid":"051ea81d-0af4-44ad-847b-60b1e686ef69","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.450016Z","iopub.execute_input":"2023-10-16T22:55:42.450321Z","iopub.status.idle":"2023-10-16T22:55:42.463220Z","shell.execute_reply.started":"2023-10-16T22:55:42.450295Z","shell.execute_reply":"2023-10-16T22:55:42.462442Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"validation_dataset = TextDataset(valid_english_sentences, valid_french_sentences)","metadata":{"_uuid":"e3925973-6e7c-4fb5-aa6e-838da53adfa5","_cell_guid":"5b882b24-cede-4bc7-a2e4-aa7c02776c8f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.463981Z","iopub.execute_input":"2023-10-16T22:55:42.464281Z","iopub.status.idle":"2023-10-16T22:55:42.475708Z","shell.execute_reply.started":"2023-10-16T22:55:42.464254Z","shell.execute_reply":"2023-10-16T22:55:42.474937Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"test_dataset = TextDataset(test_english_sentences, test_french_sentences)","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:42.476889Z","iopub.execute_input":"2023-10-16T22:55:42.477408Z","iopub.status.idle":"2023-10-16T22:55:42.489639Z","shell.execute_reply.started":"2023-10-16T22:55:42.477380Z","shell.execute_reply":"2023-10-16T22:55:42.488871Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"len(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:42.491426Z","iopub.execute_input":"2023-10-16T22:55:42.491776Z","iopub.status.idle":"2023-10-16T22:55:42.507148Z","shell.execute_reply.started":"2023-10-16T22:55:42.491747Z","shell.execute_reply":"2023-10-16T22:55:42.506255Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"1181"},"metadata":{}}]},{"cell_type":"code","source":"len(dataset)","metadata":{"_uuid":"0928bbeb-eee4-4aae-a16b-ec2b1fe0973b","_cell_guid":"e0d90023-ae18-4999-8ff5-016880b1720b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.508491Z","iopub.execute_input":"2023-10-16T22:55:42.509257Z","iopub.status.idle":"2023-10-16T22:55:42.521699Z","shell.execute_reply.started":"2023-10-16T22:55:42.509229Z","shell.execute_reply":"2023-10-16T22:55:42.520759Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"27285"},"metadata":{}}]},{"cell_type":"code","source":"len(validation_dataset)","metadata":{"_uuid":"22216a24-aca8-43c7-8565-36f54ed87380","_cell_guid":"e3545890-ea47-4c7d-9079-16d4d6cdab52","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.523384Z","iopub.execute_input":"2023-10-16T22:55:42.524708Z","iopub.status.idle":"2023-10-16T22:55:42.537781Z","shell.execute_reply.started":"2023-10-16T22:55:42.524672Z","shell.execute_reply":"2023-10-16T22:55:42.536751Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"829"},"metadata":{}}]},{"cell_type":"code","source":"validation_dataset[0]","metadata":{"_uuid":"c5ea2d7e-935d-43ee-863c-59a1eab7c044","_cell_guid":"e2c2c4da-5323-419e-bbc7-e729804df5d0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.538888Z","iopub.execute_input":"2023-10-16T22:55:42.539700Z","iopub.status.idle":"2023-10-16T22:55:42.552214Z","shell.execute_reply.started":"2023-10-16T22:55:42.539673Z","shell.execute_reply":"2023-10-16T22:55:42.551312Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"('you know, one of the intense pleasures of travel and one of the delights of ethnographic research is the opportunity to live amongst those who have not forgotten the old ways, who still feel their past in the wind, touch it in stones polished by rain, taste it in the bitter leaves of plants.',\n \"vous savez, un des plaisirs intenses du voyage et un des délices de la recherche ethnographique est la possibilité de vivre parmi ceux qui n'ont pas oublié les anciennes coutumes, qui ressentent encore leur passé souffler dans le vent, qui le touchent dans les pierres polies par la pluie, le dégustent dans les feuilles amères des plantes.\")"},"metadata":{}}]},{"cell_type":"code","source":"train_loader = DataLoader(dataset, batch_size)\niterator = iter(train_loader)","metadata":{"_uuid":"aa9bc517-a048-4871-810d-5355302c60a7","_cell_guid":"d24b65ae-3a25-4b86-8244-d4aa2516463a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.553679Z","iopub.execute_input":"2023-10-16T22:55:42.553984Z","iopub.status.idle":"2023-10-16T22:55:42.573988Z","shell.execute_reply.started":"2023-10-16T22:55:42.553957Z","shell.execute_reply":"2023-10-16T22:55:42.573119Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"validation_loader = DataLoader(validation_dataset, batch_size)","metadata":{"_uuid":"d230bf2a-c873-4e82-871f-5698bd7d9c22","_cell_guid":"b75aa97c-30db-495d-b088-bea90035f0c3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.575466Z","iopub.execute_input":"2023-10-16T22:55:42.575920Z","iopub.status.idle":"2023-10-16T22:55:42.583062Z","shell.execute_reply.started":"2023-10-16T22:55:42.575771Z","shell.execute_reply":"2023-10-16T22:55:42.581971Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"test_loader =  DataLoader(test_dataset, batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:55:42.584232Z","iopub.execute_input":"2023-10-16T22:55:42.585119Z","iopub.status.idle":"2023-10-16T22:55:42.594243Z","shell.execute_reply.started":"2023-10-16T22:55:42.585090Z","shell.execute_reply":"2023-10-16T22:55:42.593286Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"for batch_num, batch in enumerate(iterator):\n#     print(batch)\n    if batch_num > 3:\n        break","metadata":{"_uuid":"8786a5d7-54f2-45b3-96ac-5483b20555ac","_cell_guid":"75749110-722b-4ca0-82c1-a3531e083ebb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.595429Z","iopub.execute_input":"2023-10-16T22:55:42.596336Z","iopub.status.idle":"2023-10-16T22:55:42.608225Z","shell.execute_reply.started":"2023-10-16T22:55:42.596301Z","shell.execute_reply":"2023-10-16T22:55:42.607292Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from torch import nn\n\ncriterian = nn.CrossEntropyLoss(ignore_index=french_to_index[PADDING_TOKEN],\n                                reduction='none')\n\n# When computing the loss, we are ignoring cases when the label is the padding token\nfor params in transformer.parameters():\n    if params.dim() > 1:\n        nn.init.xavier_uniform_(params)\n\noptim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"_uuid":"a99ca15f-21fd-4947-bc17-48fd3da313fe","_cell_guid":"39e13797-65fe-4396-b09a-ae5b680b5277","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.609537Z","iopub.execute_input":"2023-10-16T22:55:42.610072Z","iopub.status.idle":"2023-10-16T22:55:42.675737Z","shell.execute_reply.started":"2023-10-16T22:55:42.610044Z","shell.execute_reply":"2023-10-16T22:55:42.674887Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"NEG_INFTY = -1e9\n\ndef create_masks(eng_batch, french_batch):\n    num_sentences = len(eng_batch)\n    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n\n    for idx in range(num_sentences):\n      eng_sentence_length, french_sentence_length = len(eng_batch[idx]), len(french_batch[idx])\n      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n      french_chars_to_padding_mask = np.arange(french_sentence_length + 1, max_sequence_length)\n      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n      decoder_padding_mask_self_attention[idx, :, french_chars_to_padding_mask] = True\n      decoder_padding_mask_self_attention[idx, french_chars_to_padding_mask, :] = True\n      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n      decoder_padding_mask_cross_attention[idx, french_chars_to_padding_mask, :] = True\n\n    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask","metadata":{"_uuid":"f441b29a-cd1b-48ef-914b-c6e33e528ad0","_cell_guid":"97d2d113-04f8-435f-b87c-45429cb87d3b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.676985Z","iopub.execute_input":"2023-10-16T22:55:42.677287Z","iopub.status.idle":"2023-10-16T22:55:42.684659Z","shell.execute_reply.started":"2023-10-16T22:55:42.677260Z","shell.execute_reply":"2023-10-16T22:55:42.683694Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"Modify mask such that the padding tokens cannot look ahead.\nIn Encoder, tokens before it should be -1e9 while tokens after it should be -inf.","metadata":{"_uuid":"c623342f-0dba-4454-ad3f-fb9d36b15d7c","_cell_guid":"9420b711-e0de-4549-8d88-9f4ed1b6c45c","trusted":true}},{"cell_type":"code","source":"# transformer.train()\n# transformer.to(device)\n# total_loss = 0\n# num_epochs = 2\n\n# for epoch in range(num_epochs):\n#     print(f\"Epoch {epoch}\")\n#     iterator = iter(train_loader)\n#     for batch_num, batch in enumerate(iterator):\n#         transformer.train()\n#         eng_batch, french_batch = batch\n#         encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, french_batch)\n#         optim.zero_grad()\n#         french_predictions = transformer(eng_batch,\n#                                      french_batch,\n#                                      encoder_self_attention_mask.to(device), \n#                                      decoder_self_attention_mask.to(device), \n#                                      decoder_cross_attention_mask.to(device),\n#                                      enc_start_token=False,\n#                                      enc_end_token=False,\n#                                      dec_start_token=True,\n#                                      dec_end_token=True)\n#         labels = transformer.decoder.sentence_embedding.batch_tokenize(french_batch, start_token=False, end_token=True)\n#         loss = criterian(\n#             french_predictions.view(-1, french_vocab_size).to(device),\n#             labels.view(-1).to(device)\n#         ).to(device)\n#         valid_indicies = torch.where(labels.view(-1) == french_to_index[PADDING_TOKEN], False, True)\n#         loss = loss.sum() / valid_indicies.sum()\n#         loss.backward()\n#         optim.step()\n#         #train_losses.append(loss.item())\n#         if batch_num % 100 == 0:\n#             print(f\"Iteration {batch_num} : train loss {loss.item()}\")\n# #             print(f\"English: {eng_batch[0]}\")\n# #             print(f\"french Translation: {french_batch[0]}\")\n#             french_sentence_predicted = torch.argmax(french_predictions[0], axis=1)\n#             predicted_sentence = \"\"\n#             for idx in french_sentence_predicted:\n#               if idx == french_to_index[END_TOKEN]:\n#                 break\n#               predicted_sentence += index_to_french[idx.item()]\n# #             print(f\"french Prediction: {predicted_sentence}\")\n\n\n#             transformer.eval()\n#             french_sentence = (\"\",)\n#             eng_sentence = (\"should we go to the mall?\",)\n#             for word_counter in range(max_sequence_length):\n#                 encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, french_sentence)\n#                 predictions = transformer(eng_sentence,\n#                                           french_sentence,\n#                                           encoder_self_attention_mask.to(device), \n#                                           decoder_self_attention_mask.to(device), \n#                                           decoder_cross_attention_mask.to(device),\n#                                           enc_start_token=False,\n#                                           enc_end_token=False,\n#                                           dec_start_token=True,\n#                                           dec_end_token=False)\n#                 next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n#                 next_token_index = torch.argmax(next_token_prob_distribution).item()\n#                 next_token = index_to_french[next_token_index]\n#                 french_sentence = (french_sentence[0] + next_token, )\n#                 if next_token == END_TOKEN:\n#                   break\n            \n# #             print(f\"Evaluation translation (should we go to the mall?) : {french_sentence}\")\n# #             print(\"-------------------------------------------\")","metadata":{"_uuid":"5389d39d-93d0-4d23-be89-b03e242ef6e4","_cell_guid":"5779d271-8b78-4e77-a4a8-6d089f00df53","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.685940Z","iopub.execute_input":"2023-10-16T22:55:42.686505Z","iopub.status.idle":"2023-10-16T22:55:42.705234Z","shell.execute_reply.started":"2023-10-16T22:55:42.686476Z","shell.execute_reply":"2023-10-16T22:55:42.704421Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# transformer.train()\n# transformer.to(device)\n# total_train_loss = 0\n# total_valid_loss = 0\n# num_epochs = 1\n\n# for epoch in range(num_epochs):\n#     print(f\"Epoch {epoch}\")\n    \n#     # Training phase\n#     iterator = iter(train_loader)\n#     for batch_num, batch in enumerate(iterator):\n#         transformer.train()\n#         eng_batch, french_batch = batch\n#         encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, french_batch)\n#         optim.zero_grad()\n#         french_predictions = transformer(eng_batch,\n#                                          french_batch,\n#                                          encoder_self_attention_mask.to(device), \n#                                          decoder_self_attention_mask.to(device), \n#                                          decoder_cross_attention_mask.to(device),\n#                                          enc_start_token=False,\n#                                          enc_end_token=False,\n#                                          dec_start_token=True,\n#                                          dec_end_token=True)\n#         labels = transformer.decoder.sentence_embedding.batch_tokenize(french_batch, start_token=False, end_token=True)\n#         loss = criterian(\n#             french_predictions.view(-1, french_vocab_size).to(device),\n#             labels.view(-1).to(device)\n#         ).to(device)\n#         valid_indicies = torch.where(labels.view(-1) == french_to_index[PADDING_TOKEN], False, True)\n#         loss = loss.sum() / valid_indicies.sum()\n#         loss.backward()\n#         optim.step()\n#         total_train_loss += loss.item()\n        \n#         if batch_num % 100 == 0:\n#             print(f\"Iteration {batch_num} : train loss {loss.item()}\")\n    \n#     # Validation phase\n#     transformer.eval()\n#     with torch.no_grad():\n#         valid_iterator = iter(validation_loader)\n#         for batch_num, batch in enumerate(valid_iterator):\n#             eng_batch, french_batch = batch\n#             encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, french_batch)\n#             french_predictions = transformer(eng_batch,\n#                                              french_batch,\n#                                              encoder_self_attention_mask.to(device), \n#                                              decoder_self_attention_mask.to(device), \n#                                              decoder_cross_attention_mask.to(device),\n#                                              enc_start_token=False,\n#                                              enc_end_token=False,\n#                                              dec_start_token=True,\n#                                              dec_end_token=True)\n#             labels = transformer.decoder.sentence_embedding.batch_tokenize(french_batch, start_token=False, end_token=True)\n#             valid_indicies = torch.where(labels.view(-1) == french_to_index[PADDING_TOKEN], False, True)\n#             valid_loss = criterian(\n#                 french_predictions.view(-1, french_vocab_size).to(device),\n#                 labels.view(-1).to(device)\n#             ).to(device)\n#             valid_loss = valid_loss.sum() / valid_indicies.sum()\n#             total_valid_loss += valid_loss.item()\n\n#     avg_train_loss = total_train_loss / len(train_loader)\n#     avg_valid_loss = total_valid_loss / len(validation_loader)\n    \n#     print(f\"Avg Train Loss: {avg_train_loss:.4f}\")\n#     print(f\"Avg Validation Loss: {avg_valid_loss:.4f}\")","metadata":{"_uuid":"de2a95d8-c54f-407d-9529-b2b67e2e441b","_cell_guid":"abcfec0a-c303-4676-a886-638b78604c4a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:55:42.706577Z","iopub.execute_input":"2023-10-16T22:55:42.706979Z","iopub.status.idle":"2023-10-16T22:55:42.725572Z","shell.execute_reply.started":"2023-10-16T22:55:42.706935Z","shell.execute_reply":"2023-10-16T22:55:42.724493Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"transformer.train()\ntransformer.to(device)\ntotal_train_loss = 0\ntotal_valid_loss = 0\nnum_epochs = 1\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch}\")\n    \n    # Training phase\n    iterator = iter(train_loader)\n    for batch_num, batch in enumerate(iterator):\n        transformer.train()\n        eng_batch, french_batch = batch\n        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, french_batch)\n        optim.zero_grad()\n        french_predictions = transformer(eng_batch,\n                                         french_batch,\n                                         encoder_self_attention_mask.to(device), \n                                         decoder_self_attention_mask.to(device), \n                                         decoder_cross_attention_mask.to(device),\n                                         enc_start_token=False,\n                                         enc_end_token=False,\n                                         dec_start_token=True,\n                                         dec_end_token=True)\n        labels = transformer.decoder.sentence_embedding.batch_tokenize(french_batch, start_token=False, end_token=True)\n        loss = criterian(\n            french_predictions.view(-1, french_vocab_size).to(device),\n            labels.view(-1).to(device)\n        ).to(device)\n        valid_indicies = torch.where(labels.view(-1) == french_to_index[PADDING_TOKEN], False, True)\n        loss = loss.sum() / valid_indicies.sum()\n        loss.backward()\n        optim.step()\n        total_train_loss += loss.item()\n        \n        if batch_num % 100 == 0:\n            print(f\"Iteration {batch_num} : train loss {loss.item()}\")\n    \n    # Validation phase\n    transformer.eval()\n    with torch.no_grad():\n        valid_iterator = iter(validation_loader)\n        for batch_num, batch in enumerate(valid_iterator):\n            eng_batch, french_batch = batch\n            encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, french_batch)\n            french_predictions = transformer(eng_batch,\n                                             french_batch,\n                                             encoder_self_attention_mask.to(device), \n                                             decoder_self_attention_mask.to(device), \n                                             decoder_cross_attention_mask.to(device),\n                                             enc_start_token=False,\n                                             enc_end_token=False,\n                                             dec_start_token=True,\n                                             dec_end_token=True)\n            labels = transformer.decoder.sentence_embedding.batch_tokenize(french_batch, start_token=False, end_token=True)\n            valid_indicies = torch.where(labels.view(-1) == french_to_index[PADDING_TOKEN], False, True)\n            valid_loss = criterian(\n                french_predictions.view(-1, french_vocab_size).to(device),\n                labels.view(-1).to(device)\n            ).to(device)\n            valid_loss = valid_loss.sum() / valid_indicies.sum()\n            total_valid_loss += valid_loss.item()\n\n    avg_train_loss = total_train_loss / len(train_loader)\n    avg_valid_loss = total_valid_loss / len(validation_loader)\n    \n    print(f\"Avg Train Loss: {avg_train_loss:.4f}\")\n    print(f\"Avg Validation Loss: {avg_valid_loss:.4f}\")","metadata":{"_uuid":"67e5104e-0522-401a-a14f-b5e14de16105","_cell_guid":"4b6c2803-9729-4133-8863-bcd26d1164de","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T22:58:56.525200Z","iopub.execute_input":"2023-10-16T22:58:56.525603Z","iopub.status.idle":"2023-10-16T23:03:07.893043Z","shell.execute_reply.started":"2023-10-16T22:58:56.525579Z","shell.execute_reply":"2023-10-16T23:03:07.891959Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Epoch 0\nIteration 0 : train loss 2.5501792430877686\nIteration 100 : train loss 2.4625751972198486\nIteration 200 : train loss 2.50827956199646\nIteration 300 : train loss 2.5141024589538574\nIteration 400 : train loss 2.4455456733703613\nIteration 500 : train loss 2.4382071495056152\nIteration 600 : train loss 2.3841872215270996\nIteration 700 : train loss 2.375878095626831\nIteration 800 : train loss 2.3416051864624023\nIteration 900 : train loss 2.443086862564087\nAvg Train Loss: 2.4504\nAvg Validation Loss: 2.3403\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(transformer.state_dict(), '/kaggle/working/model_weights.pth')","metadata":{"_uuid":"e6a630c3-cdc6-4927-b1f9-14d6ba0a8bf2","_cell_guid":"83142613-8a1b-40fe-a451-1ca61e3ca095","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-16T23:03:14.400770Z","iopub.execute_input":"2023-10-16T23:03:14.401121Z","iopub.status.idle":"2023-10-16T23:03:14.486292Z","shell.execute_reply.started":"2023-10-16T23:03:14.401067Z","shell.execute_reply":"2023-10-16T23:03:14.485374Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"transformer.load_state_dict(torch.load('/kaggle/working/model_weights.pth'))\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T23:03:15.962379Z","iopub.execute_input":"2023-10-16T23:03:15.963461Z","iopub.status.idle":"2023-10-16T23:03:15.992160Z","shell.execute_reply.started":"2023-10-16T23:03:15.963421Z","shell.execute_reply":"2023-10-16T23:03:15.991139Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntransformer.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T23:03:17.701397Z","iopub.execute_input":"2023-10-16T23:03:17.701714Z","iopub.status.idle":"2023-10-16T23:03:17.710957Z","shell.execute_reply.started":"2023-10-16T23:03:17.701690Z","shell.execute_reply":"2023-10-16T23:03:17.710026Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"Transformer(\n  (encoder): Encoder(\n    (sentence_embedding): SentenceEmbedding(\n      (embedding): Embedding(71, 512)\n      (position_encoder): PositionalEncoding()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layers): SequentialEncoder(\n      (0): EncoderLayer(\n        (attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (decoder): Decoder(\n    (sentence_embedding): SentenceEmbedding(\n      (embedding): Embedding(88, 512)\n      (position_encoder): PositionalEncoding()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layers): SequentialDecoder(\n      (0): DecoderLayer(\n        (self_attention): MultiHeadAttention(\n          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (encoder_decoder_attention): MultiHeadCrossAttention(\n          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (layer_norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (ffn): PositionwiseFeedForward(\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (relu): ReLU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (layer_norm3): LayerNormalization()\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (linear): Linear(in_features=512, out_features=88, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# evaluate the model on test set \n\ntransformer.eval()  # Set the model to evaluation mode\n\ntotal_test_loss = 0\n\nwith torch.no_grad():  # Ensure no gradients are computed during testing\n    test_iterator = iter(test_loader)  # Assuming you have a test_loader similar to train_loader and validation_loader\n    for batch_num, batch in enumerate(test_iterator):\n        eng_batch, french_batch = batch\n        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, french_batch)\n        french_predictions = transformer(eng_batch,\n                                         french_batch,\n                                         encoder_self_attention_mask.to(device), \n                                         decoder_self_attention_mask.to(device), \n                                         decoder_cross_attention_mask.to(device),\n                                         enc_start_token=False,\n                                         enc_end_token=False,\n                                         dec_start_token=True,\n                                         dec_end_token=True)\n        labels = transformer.decoder.sentence_embedding.batch_tokenize(french_batch, start_token=False, end_token=True)\n        valid_indicies = torch.where(labels.view(-1) == french_to_index[PADDING_TOKEN], False, True)\n        test_loss = criterian(\n            french_predictions.view(-1, french_vocab_size).to(device),\n            labels.view(-1).to(device)\n        ).to(device)\n        test_loss = test_loss.sum() / valid_indicies.sum()\n        total_test_loss += test_loss.item()\n\navg_test_loss = total_test_loss / len(test_loader)\nprint(f\"Avg Test Loss: {avg_test_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T23:03:20.566447Z","iopub.execute_input":"2023-10-16T23:03:20.566783Z","iopub.status.idle":"2023-10-16T23:03:26.947020Z","shell.execute_reply.started":"2023-10-16T23:03:20.566756Z","shell.execute_reply":"2023-10-16T23:03:26.945986Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Avg Test Loss: 2.3118\n","output_type":"stream"}]},{"cell_type":"code","source":"# from nltk.translate.bleu_score import corpus_bleu\n\n# def compute_bleu(model, data_loader, device):\n#     model.eval()\n#     all_references = []  # List of list of references\n#     all_predictions = []  # List of predictions\n\n#     with torch.no_grad():\n#         for batch in data_loader:\n#             eng_batch, french_batch = batch\n#             encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, french_batch)\n#             french_predictions = model(eng_batch,\n#                                        french_batch,\n#                                        encoder_self_attention_mask.to(device), \n#                                        decoder_self_attention_mask.to(device), \n#                                        decoder_cross_attention_mask.to(device),\n#                                        enc_start_token=False,\n#                                        enc_end_token=False,\n#                                        dec_start_token=True,\n#                                        dec_end_token=True)\n            \n#             # Convert model outputs to actual words (This will depend on how your model works. Adjust as needed.)\n#             pred_sentences = ...  # Convert `french_predictions` to list of predicted sentences\n#             ref_sentences = ...  # Convert `french_batch` to list of actual sentences\n            \n#             all_predictions.extend(pred_sentences)\n#             all_references.extend([[ref] for ref in ref_sentences])  # `corpus_bleu` expects a list of list of references\n\n#     # Compute BLEU score\n#     bleu_score = corpus_bleu(all_references, all_predictions)\n#     return bleu_score\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T22:57:36.331215Z","iopub.status.idle":"2023-10-16T22:57:36.331848Z","shell.execute_reply.started":"2023-10-16T22:57:36.331618Z","shell.execute_reply":"2023-10-16T22:57:36.331639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T23:03:35.350471Z","iopub.execute_input":"2023-10-16T23:03:35.350806Z","iopub.status.idle":"2023-10-16T23:03:36.923577Z","shell.execute_reply.started":"2023-10-16T23:03:35.350770Z","shell.execute_reply":"2023-10-16T23:03:36.922650Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_bleu(model, data_loader, device):\n    model.eval()\n    all_references = []  # List of list of references\n    all_predictions = []  # List of predictions\n\n    with torch.no_grad():\n        for batch in data_loader:\n            eng_batch, french_batch = batch\n#             print(french_batch[0][:10])\n\n            encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, french_batch)\n            french_predictions = model(eng_batch,\n                                       french_batch,\n                                       encoder_self_attention_mask.to(device), \n                                       decoder_self_attention_mask.to(device), \n                                       decoder_cross_attention_mask.to(device),\n                                       enc_start_token=False,\n                                       enc_end_token=False,\n                                       dec_start_token=True,\n                                       dec_end_token=True)\n            \n            # Convert model outputs to actual words \n            pred_sentences = convert_predictions_to_sentences(french_predictions)  # Implement this function\n            ref_sentences = convert_tensor_to_sentences(french_batch)  # Implement this function\n            \n            all_predictions.extend(pred_sentences)\n            all_references.extend([[ref] for ref in ref_sentences])  # `corpus_bleu` expects a list of list of references\n\n    # Compute BLEU score\n    bleu_score = corpus_bleu(all_references, all_predictions)\n    return bleu_score\n\n\nindex_to_word = {index: word for word, index in french_to_index.items()}\ndef convert_predictions_to_sentences(predictions_tensor):\n    # Convert logits to word indices\n    _, predicted_indices = predictions_tensor.max(dim=-1)\n    sentences = []\n    for pred in predicted_indices:\n        sentence = [index_to_word[token_idx.item()] for token_idx in pred]  # Convert tensor to integer and then lookup word\n        sentences.append(sentence)\n    return sentences\n\n\ndef convert_tensor_to_sentences(tensor):\n    # If the tensor already contains words rather than indices, return them as is\n    if isinstance(tensor[0][0], str):\n        return tensor\n    # Otherwise, convert using the index_to_word dictionary\n    sentences = []\n    for seq in tensor:\n        sentence = [index_to_word[token_idx] for token_idx in seq]\n        sentences.append(sentence)\n    return sentences\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T23:03:38.315227Z","iopub.execute_input":"2023-10-16T23:03:38.315552Z","iopub.status.idle":"2023-10-16T23:03:38.324823Z","shell.execute_reply.started":"2023-10-16T23:03:38.315528Z","shell.execute_reply":"2023-10-16T23:03:38.323715Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_bleu = compute_bleu(transformer, train_loader, device)\ntest_bleu = compute_bleu(transformer, test_loader, device)\nvalidation_bleu = compute_bleu(transformer, validation_loader, device)\n\nprint(f\"Train BLEU Score: {train_bleu:.4f}\")\nprint(f\"Test BLEU Score: {test_bleu:.4f}\")\nprint(f\"Validation BLEU Score: {validation_bleu:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T23:03:41.115848Z","iopub.execute_input":"2023-10-16T23:03:41.116220Z","iopub.status.idle":"2023-10-16T23:08:16.201047Z","shell.execute_reply.started":"2023-10-16T23:03:41.116192Z","shell.execute_reply":"2023-10-16T23:08:16.200142Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Train BLEU Score: 0.0395\nTest BLEU Score: 0.0335\nValidation BLEU Score: 0.0370\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}